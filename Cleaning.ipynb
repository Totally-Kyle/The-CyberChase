{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geoip2.database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('/Users/sa12/Documents/Repositories/The-CyberChase/DATA/feb5-12_merged.csv')\n",
    "merged_df = merged_df.replace([np.inf, -np.inf], np.nan)\n",
    "merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = geoip2.database.Reader('/Users/sa12/Documents/Repositories/The-CyberChase/DATA/GeoLite2-City.mmdb')\n",
    "# Build location info\n",
    "locations = []\n",
    "\n",
    "for ip in merged_df['Src IP']:\n",
    "    try:\n",
    "        response = reader.city(ip)\n",
    "        country = response.country.name or \"Unknown Country\"\n",
    "        city = response.city.name or \"Unknown City\"\n",
    "\n",
    "        location_str = f\"{country}\"\n",
    "    except Exception as e:\n",
    "        location_str = f\"Error: {e}\"\n",
    "\n",
    "    locations.append(location_str)\n",
    "\n",
    "# Add to DataFrame\n",
    "merged_df['Location'] = locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "90% of our data is represented in 10 columns, as such we are choosing to limit our model to those countries\n",
    "'''\n",
    "merged_df = merged_df[(merged_df['Location'] == 'Iran') | (merged_df['Location'] == 'United States') | (merged_df['Location'] == 'Hong Kong') | (merged_df['Location'] == 'China') | (merged_df['Location'] == 'Germany') | (merged_df['Location'] == 'Japan') | (merged_df['Location'] == 'Italy') | (merged_df['Location'] == 'France') | (merged_df['Location'] == 'Singapore') | (merged_df['Location'] == 'United Kingdom')]\n",
    "merged_labels = merged_df\n",
    "merged_labels['Labels'] = merged_labels['Label'].map({'ddospot':1,'cowrie':2,'adbhoney':3,'log4pot':4,'ciscoasa':5,'elasticpot':6,'mailoney':7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow ID', 'Src IP', 'Src Port', 'Timestamp', 'Flow Duration',\n",
       "       'Total Fwd Packet', 'Total Bwd packets', 'Total Length of Fwd Packet',\n",
       "       'Total Length of Bwd Packet', 'Fwd Packet Length Max',\n",
       "       'Fwd Packet Length Min', 'Fwd Packet Length Mean',\n",
       "       'Bwd Packet Length Max', 'Bwd Packet Length Min',\n",
       "       'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',\n",
       "       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max',\n",
       "       'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std',\n",
       "       'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean',\n",
       "       'Bwd IAT Max', 'Bwd IAT Min', 'Fwd Header Length', 'Bwd Header Length',\n",
       "       'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min',\n",
       "       'Packet Length Max', 'Packet Length Mean', 'Packet Length Std',\n",
       "       'Packet Length Variance', 'Down/Up Ratio', 'Average Packet Size',\n",
       "       'Fwd Segment Size Avg', 'Bwd Segment Size Avg', 'Bwd Bytes/Bulk Avg',\n",
       "       'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg', 'Subflow Fwd Packets',\n",
       "       'Subflow Fwd Bytes', 'Subflow Bwd Bytes', 'Fwd Act Data Pkts',\n",
       "       'Active Mean', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std',\n",
       "       'Idle Max', 'Idle Min', 'day', 'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.98\n",
    "dropped = []\n",
    "for col in merged_df.columns:\n",
    "    top_freq = merged_df[col].value_counts(normalize=True, dropna=False).iloc[0]\n",
    "    if top_freq > threshold:\n",
    "        dropped.append(col)\n",
    "        merged_df = merged_df.drop(columns=col)\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Country'] = merged_df['Location'].map({'Iran':1,'United States':2,'Hong Kong':3,'China':4,'Germany':5,'Japan':6,'Italy':7,'France':8,'Singapore':9,'United Kingdom':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=['Flow ID','Src IP','Src Port','Timestamp','day','Fwd Act Data Pkts', 'Fwd Header Length', \n",
    "                                    'Fwd Packet Length Mean','Total Length of Bwd Packet', 'Bwd Header Length', 'Bwd Segment Size Avg', \n",
    "                                    'Bwd Bytes/Bulk Avg','Bwd IAT Min','Bwd IAT Max', 'Bwd IAT Total','Packet Length Max','Packet Length Std',\n",
    "                                    'Packet Length Variance','Average Packet Size','Active Min','Active Max','Idle Min', 'Idle Std','Location'])\n",
    "merged_noBwd = merged_df.drop(columns=['Bwd Packet Length Max',\n",
    "       'Bwd Packet Length Min', 'Bwd Packet Length Mean',\n",
    "       'Bwd Packet Length Std','Bwd Packets/s','Bwd Packet/Bulk Avg',\n",
    "       'Bwd Bulk Rate Avg','Subflow Bwd Bytes'])\n",
    "merged_labels = merged_labels.drop(columns=['Dst IP','Dst Port','Protocol',\n",
    " 'Fwd Packet Length Std',\n",
    " 'Bwd IAT Std',\n",
    " 'Fwd PSH Flags',\n",
    " 'Bwd PSH Flags',\n",
    " 'Fwd URG Flags',\n",
    " 'Bwd URG Flags',\n",
    " 'FIN Flag Count',\n",
    " 'SYN Flag Count',\n",
    " 'RST Flag Count',\n",
    " 'PSH Flag Count',\n",
    " 'ACK Flag Count',\n",
    " 'URG Flag Count',\n",
    " 'CWR Flag Count',\n",
    " 'ECE Flag Count',\n",
    " 'Fwd Bytes/Bulk Avg',\n",
    " 'Fwd Packet/Bulk Avg',\n",
    " 'Fwd Bulk Rate Avg',\n",
    " 'Subflow Bwd Packets',\n",
    " 'FWD Init Win Bytes',\n",
    " 'Bwd Init Win Bytes',\n",
    " 'Fwd Seg Size Min',\n",
    " 'Active Std',\n",
    " 'Label'])\n",
    "merged_labels = merged_labels.drop(columns=['Flow ID','Src IP','Src Port','Timestamp','day','Fwd Act Data Pkts', 'Fwd Header Length', \n",
    "                                            'Fwd Packet Length Mean','Total Length of Bwd Packet', 'Bwd Header Length', 'Bwd Segment Size Avg', \n",
    "                                            'Bwd Bytes/Bulk Avg','Bwd IAT Min','Bwd IAT Max', 'Bwd IAT Total','Packet Length Max','Packet Length Std',\n",
    "                                            'Packet Length Variance','Average Packet Size','Active Min','Active Max','Idle Min', 'Idle Std','Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('/Users/sa12/Documents/Repositories/The-CyberChase/DATA/Clean4Model')\n",
    "merged_labels.to_csv('/Users/sa12/Documents/Repositories/The-CyberChase/DATA/Clean4Labels')\n",
    "merged_noBwd.to_csv('/Users/sa12/Documents/Repositories/The-CyberChase/DATA/CleanNoBwd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
